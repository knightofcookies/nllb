{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btech/2022/ahlad.pataparla22b/nllb/.venv/lib64/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.auto import trange\n",
    "import random\n",
    "import sys\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "import gc\n",
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df = pd.read_csv(\n",
    "    \"../../datasets/samanantar_corpus.tsv\", sep=\"\\t\\t\\t\\t\\t\", engine=\"python\"\n",
    ")\n",
    "\n",
    "parallel_train = parallel_df[0:4950000].copy()\n",
    "parallel_dev = parallel_df[4950000:4975000].copy()\n",
    "parallel_test = parallel_df[4975000:].copy()\n",
    "\n",
    "kha_mono = pd.read_csv(\n",
    "    \"../../datasets/news_kha.tsv\", sep=\"\\t\\t\\t\\t\\t\", engine=\"python\"\n",
    ")[\"kha\"].tolist()\n",
    "eng_mono = pd.read_csv(\n",
    "    \"../../datasets/high_quality_english_sentences.tsv\",\n",
    "    sep=\"\\t\\t\\t\\t\\t\",\n",
    "    engine=\"python\",\n",
    ")[\"en\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btech/2022/ahlad.pataparla22b/nllb/.venv/lib64/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpn = MosesPunctNormalizer(lang=\"en\")\n",
    "mpn.substitutions = [(re.compile(r), sub) for r, sub in mpn.substitutions]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \"):\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_index = 0\n",
    "eng_mono_index = 0\n",
    "kha_mono_index = 0\n",
    "\n",
    "def get_batch_pairs(batch_size):\n",
    "    global parallel_train\n",
    "    global parallel_index \n",
    "    if batch_size > len(parallel_train):\n",
    "        raise Exception(\"Batch size too big!\")\n",
    "    if parallel_index + batch_size > len(parallel_train):\n",
    "        parallel_train = parallel_train.sample(frac=1).reset_index(drop=True)\n",
    "        parallel_index = 0\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = parallel_train.iloc[parallel_index]\n",
    "        parallel_index += 1\n",
    "        xx.append(preproc(item[\"kha\"]))\n",
    "        yy.append(preproc(item[\"en\"]))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def get_eng_mono_batch(batch_size):\n",
    "    global eng_mono\n",
    "    global eng_mono_index\n",
    "    if batch_size > len(eng_mono):\n",
    "        raise Exception(\"Batch size too big!\")\n",
    "    if eng_mono_index + batch_size > len(eng_mono):\n",
    "        random.shuffle(eng_mono)\n",
    "        eng_mono_index = 0\n",
    "    xx = []\n",
    "    for _ in range(batch_size):\n",
    "        item = eng_mono[eng_mono_index]\n",
    "        eng_mono_index += 1\n",
    "        xx.append(preproc(item))\n",
    "    return xx\n",
    "\n",
    "def get_kha_mono_batch(batch_size):\n",
    "    global kha_mono\n",
    "    global kha_mono_index\n",
    "    if batch_size > len(kha_mono):\n",
    "        raise Exception(\"Batch size too big!\")\n",
    "    if kha_mono_index + batch_size > len(kha_mono):\n",
    "        random.shuffle(kha_mono)\n",
    "        kha_mono_index = 0\n",
    "    xx = []\n",
    "    for _ in range(batch_size):\n",
    "        item = kha_mono[kha_mono_index]\n",
    "        kha_mono_index += 1\n",
    "        xx.append(preproc(item))\n",
    "    return xx\n",
    "\n",
    "\n",
    "def encode_texts(texts, tokenizer, src_lang, max_length):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    ).to(model.device)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_length = 128\n",
    "training_steps = 60000\n",
    "losses = []\n",
    "MODEL_SAVE_PATH = \"../../saved_model/cycle_loss_nllb\"\n",
    "\n",
    "lambda_p = 1.0\n",
    "lambda_k = 1.0\n",
    "lambda_e = 1.0\n",
    "\n",
    "model.train()\n",
    "loss = None\n",
    "\n",
    "x_eng_pl = None\n",
    "x_kha_pl = None\n",
    "x_eng_mono = None\n",
    "x_kha_mono = None\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "  0%|          | 1/60000 [00:22<380:32:29, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Average Loss: 10.694738388061523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 69/60000 [19:27<238:58:42, 14.36s/it]"
     ]
    }
   ],
   "source": [
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    try:\n",
    "        kha_parallel, eng_parallel = get_batch_pairs(batch_size)\n",
    "        x_kha_pl = encode_texts(kha_parallel, tokenizer, \"vie_Latn\", max_length)\n",
    "        x_eng_pl = encode_texts(eng_parallel, tokenizer, \"eng_Latn\", max_length)\n",
    "\n",
    "        kha_mono_batch = get_kha_mono_batch(batch_size)\n",
    "        x_kha_mono = encode_texts(kha_mono_batch, tokenizer, \"vie_Latn\", max_length)\n",
    "\n",
    "        eng_mono_batch = get_eng_mono_batch(batch_size)\n",
    "        x_eng_mono = encode_texts(eng_mono_batch, tokenizer, \"eng_Latn\", max_length)\n",
    "\n",
    "        kha_to_eng = model.generate(\n",
    "            **x_kha_mono,\n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"eng_Latn\"),\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        eng_to_kha = model.generate(\n",
    "            **x_eng_mono,\n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"vie_Latn\"),\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        kha_reconstructed = model.generate(\n",
    "            input_ids=kha_to_eng,\n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"vie_Latn\"),\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        eng_reconstructed = model.generate(\n",
    "            input_ids=eng_to_kha,\n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"eng_Latn\"),\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        original_kha_embeddings = model.get_encoder()(\n",
    "            x_kha_mono.input_ids, attention_mask=x_kha_mono.attention_mask\n",
    "        ).last_hidden_state.mean(dim=1)\n",
    "        reconstructed_kha_embeddings = model.get_encoder()(\n",
    "            kha_reconstructed, attention_mask=None\n",
    "        ).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        original_eng_embeddings = model.get_encoder()(\n",
    "            x_eng_mono.input_ids, attention_mask=x_eng_mono.attention_mask\n",
    "        ).last_hidden_state.mean(dim=1)\n",
    "        reconstructed_eng_embeddings = model.get_encoder()(\n",
    "            eng_reconstructed, attention_mask=None\n",
    "        ).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        kha_cycle_loss = torch.nn.functional.mse_loss(\n",
    "            reconstructed_kha_embeddings, original_kha_embeddings\n",
    "        )\n",
    "        eng_cycle_loss = torch.nn.functional.mse_loss(\n",
    "            reconstructed_eng_embeddings, original_eng_embeddings\n",
    "        )\n",
    "\n",
    "        y_eng_pl = deepcopy(x_eng_pl)\n",
    "        y_kha_pl = deepcopy(x_kha_pl)\n",
    "        y_eng_pl.input_ids[y_eng_pl.input_ids == tokenizer.pad_token_id] = -100\n",
    "        y_kha_pl.input_ids[y_kha_pl.input_ids == tokenizer.pad_token_id] = -100\n",
    "        parallel_loss = (\n",
    "            model(\n",
    "                **x_kha_pl,\n",
    "                labels=y_eng_pl.input_ids,\n",
    "            ).loss\n",
    "            + model(\n",
    "                **x_eng_pl,\n",
    "                labels=y_kha_pl.input_ids,\n",
    "            ).loss\n",
    "        )\n",
    "\n",
    "        total_loss = (\n",
    "            lambda_p * parallel_loss\n",
    "            + lambda_k * kha_cycle_loss\n",
    "            + lambda_e * eng_cycle_loss\n",
    "        )\n",
    "        total_loss.backward()\n",
    "\n",
    "        losses.append(total_loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x_eng_pl = None\n",
    "        x_kha_pl = None\n",
    "        x_eng_mono = None\n",
    "        x_kha_mono = None\n",
    "        cleanup()\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Step {i}, Average Loss: {np.mean(losses[-1000:])}\")\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
